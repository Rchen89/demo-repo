{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "COGS_Automation_Notebook_step2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "349.091px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rchen89/demo-repo/blob/quick-test/COGS_Automation_Notebook_step2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"img/Adaptive-logo-long.png\" width=300 align=right>"
      ],
      "metadata": {
        "id": "3_xm4pLjthR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost of Sales Calculation Process Automation (Step 2)\n",
        "\n",
        "## Scope of this notebook\n",
        "\n",
        "The objective of this notebook is to provide a Read–Eval–Print Loop (REPL) tool to support the analysis for the automation of the Cost of sales calculation process. It is important to note that this notebook doesn't replace the documentation of the analysis but rather complement it. Proving a way to quickly test our assumptions, hypothesis and experiment ideas. \n",
        "\n",
        "The initial section contains mainly boilerplate code. This is a temporary measure to ensure we can mount and work with files stored in Google drive. While not optimal, this approach enable us to piggyback on the built-in authentication process.\n",
        "\n",
        "This workbook is the second step of the workbook series of Cost of Sales Calculation Process Automation. The output from the previous workbook (step 1) will be used in this workbook as the input to generate various output files\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "t8Inwb_IthSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Global Utility Parameters and Functions*"
      ],
      "metadata": {
        "id": "QedY6utxpqjk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Global Libraries"
      ],
      "metadata": {
        "id": "OaMCV2-hpqjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Global Libraries \r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from datetime import datetime, timedelta\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import seaborn as sns\r\n",
        "sns.set_theme()"
      ],
      "outputs": [],
      "metadata": {
        "id": "rbgYLQAXthSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Global Parameters\n"
      ],
      "metadata": {
        "id": "7xQvqbGb5Sap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "reporting_month_last_day = \"2021-08-31\" #@param {type:\"date\"}\r\n",
        "calculation_period = datetime.strptime(reporting_month_last_day, \"%Y-%m-%d\")\r\n",
        "calculation_period_calendar_month = calculation_period.month\r\n",
        "calculation_period_calendar_year = calculation_period.year\r\n",
        "\r\n",
        "adp_data_shared_drive_folder_id = '0AJ9N1TZkcrpeUk9PVA'\r\n",
        "department_folder_id = \"1wNSJVJWCyJ-DEOaopXMgUT8BztsmyxK-\"\r\n",
        "\r\n",
        "time_entries_with_cogs_google_folder_id = \"1YLRZYFi6PFXeQN_iLQEdMVgKKxxn-hr6\"\r\n",
        "cogs_reference_table_google_folder_id = \"139cDdEDktC28sb45F42c4sjTPzf7u-D6\"\r\n",
        "cogs_google_output_parent_folder_id = \"1WZ_3TwuNSkg341j5BQWXBMJ-O8Fk8Zee\"\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "5Omd2zTx5VPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google Authentication"
      ],
      "metadata": {
        "id": "A3FvO9XKtw-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "# Install pyDrive\r\n",
        "!pip install -U -q PyDrive2\r\n",
        "from pydrive2.auth import GoogleAuth\r\n",
        "from pydrive2.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "mycreds_file = 'mycreds.json'\r\n",
        "\r\n",
        "# This function authenticate pydrive instance and save the session credential \r\n",
        "def authenticate_pydrive():\r\n",
        "  gauth = GoogleAuth()\r\n",
        "  gauth.LoadCredentialsFile(mycreds_file)\r\n",
        "  if gauth.credentials is None:\r\n",
        "    # Authenticate if they're not there\r\n",
        "    auth.authenticate_user()\r\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "  elif gauth.access_token_expired:\r\n",
        "    # Refresh them if expired\r\n",
        "    gauth.Refresh()\r\n",
        "  else:\r\n",
        "    # Initialize the saved creds\r\n",
        "    gauth.Authorize()\r\n",
        "  # Save the current credentials to a file\r\n",
        "  gauth.SaveCredentialsFile(mycreds_file)\r\n",
        "  \r\n",
        "  drive = GoogleDrive(gauth)\r\n",
        "  return drive\r\n",
        "\r\n",
        "drive = authenticate_pydrive()"
      ],
      "outputs": [],
      "metadata": {
        "id": "fIImoQtQujki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google Drive File Handling\n"
      ],
      "metadata": {
        "id": "BhBsJZBX7r5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#This function loads the most recently modified file from a google shared drive folder based on file title, file tpye and specified folder ID\r\n",
        "def load_most_recently_modified_file_from_shared_drive_folder(file_title, file_type, parent_folder_id, retrieved_file_format, last_modified_day_offset):\r\n",
        "  last_modified_date_from_n_days_ago = (datetime.now() - timedelta(days=last_modified_day_offset)).strftime(\"%Y-%m-%dT%H:%M:%S\")\r\n",
        "  if file_title == \"\":\r\n",
        "    file_list = drive.ListFile({'q': f\"mimeType = '{file_type}' and parents in '{parent_folder_id}' and trashed=false and modifiedDate > '{last_modified_date_from_n_days_ago}'\", 'corpora': 'teamDrive', 'teamDriveId': adp_data_shared_drive_folder_id, 'includeItemsFromAllDrives': True, 'supportsAllDrives': True}).GetList()\r\n",
        "  else:\r\n",
        "    file_list = drive.ListFile({'q': f\"title contains '{file_title}' and mimeType = '{file_type}' and parents in '{parent_folder_id}' and trashed=false and modifiedDate > '{last_modified_date_from_n_days_ago}'\", 'corpora': 'teamDrive', 'teamDriveId': adp_data_shared_drive_folder_id, 'includeItemsFromAllDrives': True, 'supportsAllDrives': True}).GetList()\r\n",
        "  file_list.sort(key = lambda x : x[\"modifiedDate\"], reverse = True)\r\n",
        "\r\n",
        "  print(\"File list: \")\r\n",
        "  for file in file_list:\r\n",
        "    print(file[\"title\"] + \" | \" + file[\"id\"] + \" | \" + file[\"modifiedDate\"] + \" | \" + file[\"mimeType\"])\r\n",
        "\r\n",
        "  if(len(file_list)>0):\r\n",
        "    file_title = file_list[0][\"title\"]\r\n",
        "    file_id = file_list[0][\"id\"]\r\n",
        "    data = read_csv_from_drive(file_id,file_title)\r\n",
        "    print(\"The File loaded: \" + file_title)\r\n",
        "    if retrieved_file_format == \"file_name\":\r\n",
        "      return file_title\r\n",
        "    elif retrieved_file_format == \"file_id\":\r\n",
        "      return file_id\r\n",
        "    elif retrieved_file_format == \"data\":\r\n",
        "      return data\r\n",
        "  else:\r\n",
        "    raise NameError('No file has been found based on the current search criteria ')\r\n",
        "\r\n",
        "#This function loads the most recently modified file from google my drive folder based on file title, file tpye and specified folder ID\r\n",
        "def load_most_recently_modified_file_from_my_drive_folder(file_title, file_type, parent_folder_id, retrieved_file_format, last_modified_day_offset):\r\n",
        "  last_modified_date_from_n_days_ago = (datetime.now() - timedelta(days=last_modified_day_offset)).strftime(\"%Y-%m-%dT%H:%M:%S\")\r\n",
        "  if file_title == \"\":\r\n",
        "    file_list = drive.ListFile({'q': f\"mimeType = '{file_type}' and parents in '{parent_folder_id}' and trashed=false and modifiedDate > '{last_modified_date_from_n_days_ago}'\" }).GetList()\r\n",
        "  else:\r\n",
        "    file_list = drive.ListFile({'q': f\"title contains '{file_title}' and mimeType = '{file_type}' and parents in '{parent_folder_id}' and trashed=false and modifiedDate > '{last_modified_date_from_n_days_ago}'\" }).GetList()\r\n",
        "  file_list.sort(key = lambda x : x[\"modifiedDate\"], reverse = True)\r\n",
        "\r\n",
        "  print(\"File list: \")\r\n",
        "  for file in file_list:\r\n",
        "    print(file[\"title\"] + \" | \" + file[\"id\"] + \" | \" + file[\"modifiedDate\"] + \" | \" + file[\"mimeType\"])\r\n",
        "\r\n",
        "  if(len(file_list)>0):\r\n",
        "    file_title = file_list[0][\"title\"]\r\n",
        "    file_id = file_list[0][\"id\"]\r\n",
        "    data = read_csv_from_drive(file_id,file_title)\r\n",
        "    print(\"The File loaded: \" + file_title)\r\n",
        "    if retrieved_file_format == \"file_name\":\r\n",
        "      return file_title\r\n",
        "    elif retrieved_file_format == \"file_id\":\r\n",
        "      return file_id\r\n",
        "    elif retrieved_file_format == \"data\":\r\n",
        "      return data\r\n",
        "  else:\r\n",
        "    raise NameError('No file has been found based on the current search criteria ') \r\n",
        "\r\n",
        "#This function loads the most recently modified folder from a parent google drive folder based on the specified parent folder ID\r\n",
        "def load_most_recently_modified_folder_from_specified_folder(parent_folder_id, last_modified_day_offset):\r\n",
        "  last_modified_date_from_n_days_ago = (datetime.now() - timedelta(days=last_modified_day_offset)).strftime(\"%Y-%m-%dT%H:%M:%S\")\r\n",
        "  folder_list = drive.ListFile({'q': f\"mimeType = '{'application/vnd.google-apps.folder'}' and parents in '{parent_folder_id}' and trashed=false and modifiedDate > '{last_modified_date_from_n_days_ago}'\" }).GetList()\r\n",
        "  folder_list.sort(key = lambda x : x[\"modifiedDate\"], reverse = True)\r\n",
        "\r\n",
        "  print(\"Folder list: \")\r\n",
        "  for folder in folder_list:\r\n",
        "    print(folder[\"title\"] + \" | \" + folder[\"id\"] + \" | \" + folder[\"modifiedDate\"] + \" | \" + folder[\"mimeType\"])\r\n",
        "\r\n",
        "  if(len(folder)>0):\r\n",
        "    folder_title = folder_list[0][\"title\"]\r\n",
        "    folder_id = folder_list[0][\"id\"]\r\n",
        "    print(\"The File loaded: \" + folder_id)\r\n",
        "    return folder_id\r\n",
        "  else:\r\n",
        "    raise NameError('No folder has been found based on the current search criteria ')\r\n",
        "\r\n",
        "#This function read the csv file based on specified file id from the google drive \r\n",
        "def read_csv_from_drive(file_id, file_name):\r\n",
        "    dl = drive.CreateFile({'id': file_id})\r\n",
        "    dl.GetContentFile(file_name)\r\n",
        "    return pd.read_csv(file_name)\r\n",
        "\r\n",
        "#This function read the csv file based on specified file id from the google drive \r\n",
        "def upload_file_to_google_drive(output_file_name, file_mime_type, google_drive_folder_id, temp_filename):\r\n",
        "    file_upload = drive.CreateFile({\"title\":output_file_name,\r\n",
        "                                    \"mimeType\": file_mime_type, \r\n",
        "                                    \"parents\" : [{\"id\" : google_drive_folder_id}]})\r\n",
        "    file_upload.SetContentFile(temp_filename)\r\n",
        "    file_upload.Upload()\r\n",
        "    print('Uploaded file with ID {}'.format(file_upload.get('id')))\r\n",
        "\r\n",
        "# This function converts dataframe into csv file and upload it to specified folder in google drive\r\n",
        "def upload_file_to_drive_csv_format(data, google_drive_folder_id, output_file_name, index_included):\r\n",
        "    temp_filename = \"data.csv\"\r\n",
        "    if index_included == True:\r\n",
        "      data.to_csv(temp_filename,index=True)\r\n",
        "    else:\r\n",
        "      data.to_csv(temp_filename,index=False)\r\n",
        "    google_drive_folder_id = google_drive_folder_id\r\n",
        "    output_file_name = output_file_name\r\n",
        "    upload_file_to_google_drive(output_file_name, \"text/csv\", google_drive_folder_id, temp_filename)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "euSRfw4m7vy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Cleasing functions\n"
      ],
      "metadata": {
        "id": "srm-4sG-XQIa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Set the data type to mulitiple columns of a dataframe\r\n",
        "def set_column_data_type(data,col_list,data_type):\r\n",
        "    data_copy = data.copy()\r\n",
        "    data_copy[col_list] = data_copy[col_list].astype(data_type)\r\n",
        "    return data_copy"
      ],
      "outputs": [],
      "metadata": {
        "id": "IWgB8LeaXgck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reference Data\n"
      ],
      "metadata": {
        "id": "gcIFg7Nsor36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Xero Department Code Mappings\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XoEcMUrmovJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "xero_department_code_mapping = load_most_recently_modified_file_from_shared_drive_folder(\"departments\",'text/csv',department_folder_id, \"data\", 365)\r\n",
        "xero_department_code_mapping.set_index(\"department_name\", inplace = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "34H-j2n3orS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load time entries with calculated costs dataframe"
      ],
      "metadata": {
        "id": "uOXA5uXdWREi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Find the folder which the most recently processed time entry file is stored "
      ],
      "metadata": {
        "id": "mvRa2laf44Ig"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "most_recent_cleansed_time_entry_file_folder_id = load_most_recently_modified_folder_from_specified_folder(cogs_google_output_parent_folder_id, 365)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jHMRiHwY2yEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Helper Functions\n"
      ],
      "metadata": {
        "id": "pipIo6sPz4R8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# This function retrieve the time stamp from the processed time entry file from step 1 script\r\n",
        "def derive_output_time_stamp(file_name):\r\n",
        "  timestamp_splitter = \"|\"\r\n",
        "  index = file_name.find(timestamp_splitter)\r\n",
        "  return file_name[index+1:len(file_name)-4]\r\n",
        "\r\n",
        "# This function derives the department code for AI template\r\n",
        "def derive_department_code_for_AI_template(row):\r\n",
        "  business_unit_mapping_for_AI = {\r\n",
        "      \"Adaptive Canada\" : \"MTL\",\r\n",
        "      \"Adaptive UK\" : \"LDN\",\r\n",
        "      \"Adaptive US\" : \"NY\",\r\n",
        "      \"Adaptive Spain\" : \"BCN\"\r\n",
        "  }\r\n",
        "  resource_BU = row[\"resource_BU\"]\r\n",
        "  adp_department = row[\"adp_department\"]\r\n",
        "  \r\n",
        "  return adp_department + \" - \" + business_unit_mapping_for_AI[resource_BU]\r\n",
        "\r\n",
        "# This function derives the reference column in the output file \r\n",
        "def derive_reference_column(row):\r\n",
        "  resourced_activity = row[\"resourced_activity\"]\r\n",
        "  delivery_element_reference = row[\"delivery_element_reference\"]\r\n",
        "  if delivery_element_reference != \"n/a\":\r\n",
        "    return delivery_element_reference\r\n",
        "  else:\r\n",
        "    return resourced_activity\r\n",
        "\r\n",
        "# This function derives the tax rate column on the journal entry template\r\n",
        "def derive_journal_tax_rate(row):\r\n",
        "  return \"Tax Exempt\"\r\n",
        "\r\n",
        "# This function filters the full journal entry dataframe by each business unit, then upload the resulting dataframe as csv file to target google drive folder\r\n",
        "def process_cogs_journal_entry_by_BU(df_journal_entris_all, business_unit, output_batch_code):\r\n",
        "  cogs_journal_template_final_BU = cogs_journal_template_final[cogs_journal_template_final[\"Entity\"] == business_unit]\r\n",
        "  cogs_journal_template_file_name = \"COGS - Journal Template Output_\" + business_unit + \" | \" + output_time_stamp + \".csv\"\r\n",
        "  upload_file_to_drive_csv_format(cogs_journal_template_final_BU, most_recent_cleansed_time_entry_file_folder_id, cogs_journal_template_file_name, False)\r\n",
        "  return cogs_journal_template_final_BU\r\n",
        "    \r\n",
        "# This function derives the line description for B/S reconciliation file    \r\n",
        "def derive_bs_acc_line_description(row):\r\n",
        "  entry_units_by_day = row[\"entry_units_by_day\"]\r\n",
        "  daily_rate = row[\"bamboohr_cost_rate_daily\"]\r\n",
        "  resource = row[\"resource\"]\r\n",
        "\r\n",
        "  return str(calculation_period_calendar_month) + \"-\" + str(calculation_period_calendar_year) + \" \" + resource + \" \" + str(round(entry_units_by_day, 3)) + \" days at \" + str(daily_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "5t2FYx8bz3kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the most recently processed time entry file with calculated costs"
      ],
      "metadata": {
        "id": "TJQfsS2-5FQj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_with_calculated_cost_file_name = load_most_recently_modified_file_from_my_drive_folder('COGS_Output_2_Kimble_Time_Entries', 'text/csv', most_recent_cleansed_time_entry_file_folder_id, \"file_name\", 30)\r\n",
        "output_time_stamp =  derive_output_time_stamp(time_entries_with_calculated_cost_file_name)\r\n",
        "time_entries_with_calculated_cost = load_most_recently_modified_file_from_my_drive_folder('COGS_Output_2_Kimble_Time_Entries', 'text/csv', most_recent_cleansed_time_entry_file_folder_id, \"data\", 30)\r\n",
        "time_entries_with_calculated_cost.loc[time_entries_with_calculated_cost[\"cost_GL\"].notnull(), \"cost_GL\"] = time_entries_with_calculated_cost.loc[time_entries_with_calculated_cost[\"cost_GL\"].notnull(), \"cost_GL\"].astype(int).astype(str)\r\n",
        "time_entries_with_calculated_cost.loc[time_entries_with_calculated_cost[\"contra_GL\"].notnull(), \"contra_GL\"] = time_entries_with_calculated_cost.loc[time_entries_with_calculated_cost[\"contra_GL\"].notnull(), \"contra_GL\"].astype(int).astype(str)\r\n",
        "time_entries_with_calculated_cost[\"reference\"] = time_entries_with_calculated_cost.apply(lambda row: derive_reference_column(row), axis=1)\r\n",
        "time_entries_with_calculated_cost.fillna(\"n/a\",inplace = True)\r\n",
        "time_entries_with_calculated_cost.head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "-7xzFnFfWX5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate AI Upload Template \n"
      ],
      "metadata": {
        "id": "pRbK8gVUp1ug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_pivot_table_for_AI_template = pd.pivot_table(time_entries_with_calculated_cost, index=[\"resource_BU\", \"resource\", \"resource_id\", \"resource_type\", \"cost_GL\", \"resourced_activity\", \"adp_department\", \"delivery_element_reference\", \"adp_revenue_cost_category\"], values = [\"cost_for_activity\", \"entry_units_by_day\"], aggfunc=\"sum\")\r\n",
        "\r\n",
        "time_entries_pivot_table_for_AI_template"
      ],
      "outputs": [],
      "metadata": {
        "id": "rn02UH1gsgJi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_pivot_table_flattened_for_AI_template = pd.DataFrame(time_entries_pivot_table_for_AI_template.to_records())\r\n",
        "time_entries_pivot_table_flattened_for_AI_template[\"department_code_AI\"] = time_entries_pivot_table_flattened_for_AI_template.apply(lambda row: derive_department_code_for_AI_template(row), axis=1)\r\n",
        "time_entries_pivot_table_flattened_for_AI_template[\"reference\"] = time_entries_pivot_table_flattened_for_AI_template.apply(lambda row: derive_reference_column(row), axis=1)\r\n",
        "time_entries_pivot_table_flattened_for_AI_template = time_entries_pivot_table_flattened_for_AI_template[time_entries_pivot_table_flattened_for_AI_template[\"cost_GL\"].str.startswith(\"5\")]\r\n",
        "column_order = [\"department_code_AI\", \"resource\", \"resource_id\", \"resource_type\", \"cost_for_activity\", \"entry_units_by_day\", \"reference\", \"adp_revenue_cost_category\", \"adp_department\"]\r\n",
        "time_entries_pivot_table_flattened_for_AI_template = time_entries_pivot_table_flattened_for_AI_template[column_order]\r\n",
        "time_entries_pivot_table_flattened_for_AI_template\r\n",
        "\r\n",
        "cogs_AI_template_file_name = \"COGS - AI Template Output\" + \" | \" + output_time_stamp + \".csv\"\r\n",
        "upload_file_to_drive_csv_format(time_entries_pivot_table_flattened_for_AI_template, most_recent_cleansed_time_entry_file_folder_id, cogs_AI_template_file_name, False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "0LkxaubVzgm6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_pivot_table_flattened_for_AI_template_by_days = time_entries_pivot_table_flattened_for_AI_template\r\n",
        "column_order_by_days =  [\"department_code_AI\", \"resource\", \"resource_id\", \"resource_type\", \"reference\", \"adp_department\", \"entry_units_by_day\"]\r\n",
        "time_entries_pivot_table_flattened_for_AI_template_by_days = time_entries_pivot_table_flattened_for_AI_template_by_days[column_order_by_days]\r\n",
        "\r\n",
        "cogs_by_days_AI_template_file_name = \"COGS - AI Template Output - by days\" + \" | \" + output_time_stamp + \".csv\"\r\n",
        "upload_file_to_drive_csv_format(time_entries_pivot_table_flattened_for_AI_template_by_days, most_recent_cleansed_time_entry_file_folder_id, cogs_by_days_AI_template_file_name, False)\r\n",
        "\r\n",
        "\r\n",
        "time_entries_pivot_table_flattened_for_AI_template_by_cost = time_entries_pivot_table_flattened_for_AI_template\r\n",
        "column_order_by_costs = [\"department_code_AI\", \"resource\", \"resource_id\", \"reference\", \"resource_type\", \"adp_department\", \"cost_for_activity\"]\r\n",
        "time_entries_pivot_table_flattened_for_AI_template_by_cost = time_entries_pivot_table_flattened_for_AI_template_by_cost[column_order_by_costs]\r\n",
        "\r\n",
        "cogs_by_costs_AI_template_file_name = \"COGS - AI Template Output - by costs\" + \" | \" + output_time_stamp + \".csv\"\r\n",
        "upload_file_to_drive_csv_format(time_entries_pivot_table_flattened_for_AI_template_by_cost, most_recent_cleansed_time_entry_file_folder_id, cogs_by_costs_AI_template_file_name, False)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "u4ij2cVXeubI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate Journal Entry Upload Template "
      ],
      "metadata": {
        "id": "Y6LqDkF5Voov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_pivot_table_for_journal_template = pd.pivot_table(time_entries_with_calculated_cost, index=[\"resource_BU\", \"cost_GL\", \"adp_department\", \"contra_GL\", \"resource_department\", \"resourced_activity\", \"delivery_element_reference\"], values = [\"cost_for_activity\"], aggfunc=\"sum\")\r\n",
        "time_entries_pivot_table_for_journal_template"
      ],
      "outputs": [],
      "metadata": {
        "id": "4gKK4JKJV0m1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# time_entries_pivot_table_flattened_for_journal_template = pd.DataFrame(time_entries_pivot_table_for_journal_template.to_records())\r\n",
        "# upload_file_to_drive_csv_format(time_entries_pivot_table_flattened_for_journal_template, most_recent_cleansed_time_entry_file_folder_id, \"test_journal_pivot_data.csv\", False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "i-2tUebUdia7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_pivot_table_flattened_for_journal_template = pd.DataFrame(time_entries_pivot_table_for_journal_template.to_records())\r\n",
        "time_entries_pivot_table_flattened_for_journal_template = time_entries_pivot_table_flattened_for_journal_template[time_entries_pivot_table_flattened_for_journal_template[\"cost_GL\"] != \"n/a\"]\r\n",
        "time_entries_pivot_table_flattened_for_journal_template[\"cost_for_activity\"] = time_entries_pivot_table_flattened_for_journal_template[\"cost_for_activity\"].round(2) \r\n",
        "time_entries_pivot_table_flattened_for_journal_template[\"Entity\"] = time_entries_pivot_table_flattened_for_journal_template[\"resource_BU\"]\r\n",
        "time_entries_pivot_table_flattened_for_journal_template[\"Date\"] = reporting_month_last_day\r\n",
        "time_entries_pivot_table_flattened_for_journal_template[\"Description\"] = \"COGS \" + str(calculation_period_calendar_month) + \"-\" + str(calculation_period_calendar_year)\r\n",
        "time_entries_pivot_table_flattened_for_journal_template[\"Narration\"] = \"COGS \" + str(calculation_period_calendar_month) + \"-\" + str(calculation_period_calendar_year) + \" - \" + \"See Cogs files for back up\"\r\n",
        "time_entries_pivot_table_flattened_for_journal_template[\"Tax Rate\"] = time_entries_pivot_table_flattened_for_journal_template.apply(lambda row: derive_journal_tax_rate(row), axis = 1)\r\n",
        "time_entries_pivot_table_flattened_for_journal_template[\"TrackingOption1\"] = time_entries_pivot_table_flattened_for_journal_template[\"adp_department\"].map(xero_department_code_mapping[\"xero_department_name\"])\r\n",
        "time_entries_pivot_table_flattened_for_journal_template[\"TrackingOption2\"] = time_entries_pivot_table_flattened_for_journal_template.apply(lambda row: derive_reference_column(row), axis=1)\r\n",
        "time_entries_pivot_table_flattened_for_journal_template"
      ],
      "outputs": [],
      "metadata": {
        "id": "GY3cVth2hkzU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cogs_journal_template_debit_lines = time_entries_pivot_table_flattened_for_journal_template.copy()\r\n",
        "cogs_journal_template_debit_lines[\"Accounting Code\"] = cogs_journal_template_debit_lines[\"cost_GL\"]\r\n",
        "cogs_journal_template_debit_lines[\"Amount\"] = cogs_journal_template_debit_lines[\"cost_for_activity\"]\r\n",
        "journal_columns = [\"Entity\", \"Date\", \"Description\", \"Narration\", \"Accounting Code\", \"Tax Rate\", \"Amount\", \"TrackingOption1\", \"TrackingOption2\"]\r\n",
        "cogs_journal_template_debit_lines = cogs_journal_template_debit_lines[journal_columns]\r\n",
        "cogs_journal_template_debit_lines"
      ],
      "outputs": [],
      "metadata": {
        "id": "JYdIB0zWhqjg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cogs_journal_template_credit_lines = time_entries_pivot_table_flattened_for_journal_template.copy()\r\n",
        "cogs_journal_template_credit_lines[\"Accounting Code\"] = cogs_journal_template_credit_lines[\"contra_GL\"]\r\n",
        "cogs_journal_template_credit_lines[\"Amount\"] = cogs_journal_template_credit_lines[\"cost_for_activity\"] * -1\r\n",
        "journal_columns = [\"Entity\", \"Date\", \"Description\", \"Narration\", \"Accounting Code\", \"Tax Rate\", \"Amount\", \"TrackingOption1\", \"TrackingOption2\"]\r\n",
        "cogs_journal_template_credit_lines = cogs_journal_template_credit_lines[journal_columns]\r\n",
        "cogs_journal_template_credit_lines"
      ],
      "outputs": [],
      "metadata": {
        "id": "C0s_Q_n06eOW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cogs_journal_template_final = pd.concat([cogs_journal_template_debit_lines, cogs_journal_template_credit_lines],axis = 0)\r\n",
        "cogs_journal_template_final"
      ],
      "outputs": [],
      "metadata": {
        "id": "n1_Ie8A06o-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cogs_journal_template_final_uk = process_cogs_journal_entry_by_BU(cogs_journal_template_final, \"Adaptive UK\", output_time_stamp)\r\n",
        "cogs_journal_template_final_us = process_cogs_journal_entry_by_BU(cogs_journal_template_final, \"Adaptive US\", output_time_stamp)\r\n",
        "cogs_journal_template_final_spain = process_cogs_journal_entry_by_BU(cogs_journal_template_final, \"Adaptive Spain\", output_time_stamp)\r\n",
        "cogs_journal_template_final_canada = process_cogs_journal_entry_by_BU(cogs_journal_template_final, \"Adaptive Canada\", output_time_stamp)"
      ],
      "outputs": [],
      "metadata": {
        "id": "_L8W4KII81k2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Contractor BS rec acc LC"
      ],
      "metadata": {
        "id": "YMl6VPBDxaBQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_with_calculated_cost_contractors = time_entries_with_calculated_cost[time_entries_with_calculated_cost[\"resource_type\"] == \"Contractor\"]\r\n",
        "time_entries_with_calculated_cost_contractors"
      ],
      "outputs": [],
      "metadata": {
        "id": "P8xZwmwz2Fmq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_pivot_for_bs_acc_contractor = pd.pivot_table(time_entries_with_calculated_cost_contractors, index=[\"resource_BU\", \"contra_GL\", \"resource\", \"bamboohr_cost_rate_daily\", \"delivery_element_shortname\", \"delivery_element_reference\", \"adp_department\"], values = [\"entry_units_by_day\", \"cost_for_activity\"], aggfunc=\"sum\")\r\n",
        "time_entries_pivot_for_bs_acc_contractor"
      ],
      "outputs": [],
      "metadata": {
        "id": "hf4UYp832Hjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "time_entries_pivot_flatterned_for_bs_acc_contractor = pd.DataFrame(time_entries_pivot_for_bs_acc_contractor.to_records())\r\n",
        "time_entries_pivot_flatterned_for_bs_acc_contractor[\"description\"] = time_entries_pivot_flatterned_for_bs_acc_contractor.apply(lambda row: derive_bs_acc_line_description(row), axis = 1)\r\n",
        "time_entries_pivot_flatterned_for_bs_acc_contractor[\"cost_on_bs\"] = time_entries_pivot_flatterned_for_bs_acc_contractor[\"cost_for_activity\"] * -1\r\n",
        "time_entries_pivot_flatterned_for_bs_acc_contractor = time_entries_pivot_flatterned_for_bs_acc_contractor[time_entries_pivot_flatterned_for_bs_acc_contractor[\"cost_on_bs\"] != 0]\r\n",
        "ordered_columns = [\"resource_BU\", \"resource\", \"bamboohr_cost_rate_daily\", \"entry_units_by_day\", \"cost_for_activity\", \"cost_on_bs\", \"description\", \"delivery_element_reference\", \"delivery_element_shortname\", \"adp_department\"]\r\n",
        "time_entries_pivot_flatterned_for_bs_acc_contractor = time_entries_pivot_flatterned_for_bs_acc_contractor[ordered_columns]\r\n",
        "time_entries_pivot_flatterned_for_bs_acc_contractor\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "5K59LGiZ2JYg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cogs_bs_acc_file_name = \"COGS - B/S acc Output\" + \" | \" + output_time_stamp + \".csv\"\r\n",
        "upload_file_to_drive_csv_format(time_entries_pivot_flatterned_for_bs_acc_contractor, most_recent_cleansed_time_entry_file_folder_id, cogs_bs_acc_file_name, False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "MqPsaCL0-JZ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a new line ok\r\n"
      ],
      "metadata": {}
    }
  ]
}